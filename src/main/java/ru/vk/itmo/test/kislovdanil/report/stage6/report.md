# Отчёт о нагрузочном тестировании

## Этап 6

* Тестирование производилось при 10000 RPS(GET) на 4 потока с одним 64 соединяниями.
* Один инстанс базы данных
* flushThresholdBytes 10Mb
* База заполнена на 190 Mb всеми ключами от 0 до 100000.
* Обработкой запросов занимется ThreadPoolExecutor с очередью на 100000 задач,
  пулом 24 потока
* Для тестирования была использована утилита wrk2.
* Для профилирования был использован async-profiler внутри IntelliJ IDEA

### Скрипты

* [getrange.lua](../scripts/getrange.lua)

### Результаты

[Вывод wrk2 для GET](getrange.txt)

![](Histogram.png)

#### Флеймграфы для GET запросов

##### CPU

![](getCpu.png)

##### Allocations

![](getMemory.png)

### Вывод

Изначальная реализация DAO не читала в оперативную память
весь range, поэтому проблем с решением для этапа не возникло.
Большая часть времени уходит на передачу данных; чтобы уменьшить latency
можно попробовать добавить сжатие данных или как-то ускорить передачу
данных

Можно заметить, что довольно много памяти выделяется при отправке
чанка, т.к. его содержание копируется в буфер. Это осознанное решение,
если отправлять данные последовательно вызывая session.write на массивах байтов
[уходит в 4-5 раз больше времени](getrange_sqeuntial_write.txt).
Нагрузочное тестирование с wrk2 на данном этапе имеет мало смысла т.к. почти всё
время уходит на запись 190Mb в сессию и для всех запросов уходит одинаковое время,
приложил вывод только чтобы можно было посмотреть latency такого запроса.